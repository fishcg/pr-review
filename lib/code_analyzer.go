package lib

import (
	"fmt"
	"os/exec"
	"path/filepath"
	"regexp"
	"strings"
)

// CodeAnalyzer ä»£ç åˆ†æå™¨
type CodeAnalyzer struct {
	workDir       string
	modifiedFiles []string
	diffText      string
}

// NewCodeAnalyzer åˆ›å»ºä»£ç åˆ†æå™¨
func NewCodeAnalyzer(workDir string, modifiedFiles []string, diffText string) *CodeAnalyzer {
	return &CodeAnalyzer{
		workDir:       workDir,
		modifiedFiles: modifiedFiles,
		diffText:      diffText,
	}
}

// FunctionInfo å‡½æ•°ä¿¡æ¯
type FunctionInfo struct {
	Name     string
	File     string
	Language string
	Type     string // "function", "method", "class", "interface"
}

// DependencyAnalysisResult ä¾èµ–åˆ†æç»“æœ
type DependencyAnalysisResult struct {
	ModifiedFunctions []FunctionInfo
	CallSites         map[string][]string // function name -> file paths
	TestCoverage      map[string][]string // source file -> test files
	MissingTests      []string            // files without tests
}

// AnalyzeDependencies åˆ†æä¾èµ–å½±å“å’Œæµ‹è¯•è¦†ç›–
func (a *CodeAnalyzer) AnalyzeDependencies() *DependencyAnalysisResult {
	result := &DependencyAnalysisResult{
		ModifiedFunctions: []FunctionInfo{},
		CallSites:         make(map[string][]string),
		TestCoverage:      make(map[string][]string),
		MissingTests:      []string{},
	}

	// 1. æå–ä¿®æ”¹çš„å‡½æ•°/æ–¹æ³•/ç±»
	for _, file := range a.modifiedFiles {
		functions := a.extractModifiedFunctions(file)
		result.ModifiedFunctions = append(result.ModifiedFunctions, functions...)
	}

	// 2. æŸ¥æ‰¾å‡½æ•°è°ƒç”¨ä½ç½®
	for _, fn := range result.ModifiedFunctions {
		callSites := a.findCallSites(fn.Name, fn.File)
		if len(callSites) > 0 {
			result.CallSites[fn.Name] = callSites
		}
	}

	// 3. æ£€æŸ¥æµ‹è¯•è¦†ç›–
	for _, file := range a.modifiedFiles {
		testFiles := a.findTestFiles(file)
		if len(testFiles) > 0 {
			result.TestCoverage[file] = testFiles
		} else {
			result.MissingTests = append(result.MissingTests, file)
		}
	}

	return result
}

// extractModifiedFunctions ä» diff ä¸­æå–ä¿®æ”¹çš„å‡½æ•°
func (a *CodeAnalyzer) extractModifiedFunctions(file string) []FunctionInfo {
	functions := []FunctionInfo{}
	language := detectLanguage(file)

	// æ ¹æ®è¯­è¨€é€‰æ‹©ä¸åŒçš„å‡½æ•°æå–ç­–ç•¥
	patterns := getFunctionPatterns(language)
	if len(patterns) == 0 {
		return functions
	}

	// ä» diff ä¸­æå–ä¿®æ”¹çš„ä»£ç è¡Œ
	addedLines := a.extractAddedOrModifiedLines(file)

	for _, line := range addedLines {
		for _, pattern := range patterns {
			re := regexp.MustCompile(pattern.Regex)
			if matches := re.FindStringSubmatch(line); matches != nil && len(matches) > 1 {
				funcName := matches[1]
				// è¿‡æ»¤æ‰ä¸€äº›æ˜æ˜¾çš„è¯¯æŠ¥
				if !isValidFunctionName(funcName) {
					continue
				}
				functions = append(functions, FunctionInfo{
					Name:     funcName,
					File:     file,
					Language: language,
					Type:     pattern.Type,
				})
			}
		}
	}

	return functions
}

// extractAddedOrModifiedLines ä» diff ä¸­æå–æ–°å¢æˆ–ä¿®æ”¹çš„ä»£ç è¡Œ
func (a *CodeAnalyzer) extractAddedOrModifiedLines(file string) []string {
	lines := []string{}
	diffLines := strings.Split(a.diffText, "\n")

	inTargetFile := false
	for _, line := range diffLines {
		// æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡æ–‡ä»¶
		if strings.HasPrefix(line, "+++ b/") {
			currentFile := strings.TrimPrefix(line, "+++ b/")
			inTargetFile = (currentFile == file)
			continue
		}

		if !inTargetFile {
			continue
		}

		// æå–æ–°å¢çš„ä»£ç è¡Œï¼ˆä»¥ + å¼€å¤´ï¼Œä½†ä¸æ˜¯ +++ï¼‰
		if strings.HasPrefix(line, "+") && !strings.HasPrefix(line, "+++") {
			lines = append(lines, strings.TrimPrefix(line, "+"))
		}
	}

	return lines
}

// FunctionPattern å‡½æ•°åŒ¹é…æ¨¡å¼
type FunctionPattern struct {
	Regex string
	Type  string
}

// getFunctionPatterns è·å–ä¸åŒè¯­è¨€çš„å‡½æ•°åŒ¹é…æ¨¡å¼
func getFunctionPatterns(language string) []FunctionPattern {
	patterns := make([]FunctionPattern, 0)

	switch language {
	case "Go":
		patterns = append(patterns,
			FunctionPattern{Regex: `^\s*func\s+(\w+)\s*\(`, Type: "function"},
			FunctionPattern{Regex: `^\s*func\s+\([^)]+\)\s+(\w+)\s*\(`, Type: "method"},
			FunctionPattern{Regex: `^\s*type\s+(\w+)\s+struct`, Type: "struct"},
			FunctionPattern{Regex: `^\s*type\s+(\w+)\s+interface`, Type: "interface"},
		)
	case "JavaScript", "TypeScript", "React", "React/TypeScript":
		patterns = append(patterns,
			FunctionPattern{Regex: `^\s*function\s+(\w+)\s*\(`, Type: "function"},
			FunctionPattern{Regex: `^\s*const\s+(\w+)\s*=\s*\([^)]*\)\s*=>`, Type: "function"},
			FunctionPattern{Regex: `^\s*export\s+function\s+(\w+)\s*\(`, Type: "function"},
			FunctionPattern{Regex: `^\s*class\s+(\w+)`, Type: "class"},
			FunctionPattern{Regex: `^\s*(\w+)\s*:\s*function\s*\(`, Type: "method"},
			FunctionPattern{Regex: `^\s*(\w+)\s*\([^)]*\)\s*{`, Type: "method"},
		)
	case "Python":
		patterns = append(patterns,
			FunctionPattern{Regex: `^\s*def\s+(\w+)\s*\(`, Type: "function"},
			FunctionPattern{Regex: `^\s*class\s+(\w+)`, Type: "class"},
			FunctionPattern{Regex: `^\s*async\s+def\s+(\w+)\s*\(`, Type: "function"},
		)
	case "Java":
		patterns = append(patterns,
			FunctionPattern{Regex: `^\s*(?:public|private|protected)?\s*(?:static)?\s*\w+\s+(\w+)\s*\(`, Type: "method"},
			FunctionPattern{Regex: `^\s*(?:public|private|protected)?\s*class\s+(\w+)`, Type: "class"},
			FunctionPattern{Regex: `^\s*(?:public|private|protected)?\s*interface\s+(\w+)`, Type: "interface"},
		)
	case "Rust":
		patterns = append(patterns,
			FunctionPattern{Regex: `^\s*fn\s+(\w+)\s*\(`, Type: "function"},
			FunctionPattern{Regex: `^\s*pub\s+fn\s+(\w+)\s*\(`, Type: "function"},
			FunctionPattern{Regex: `^\s*struct\s+(\w+)`, Type: "struct"},
			FunctionPattern{Regex: `^\s*trait\s+(\w+)`, Type: "trait"},
		)
	case "C++", "C":
		patterns = append(patterns,
			FunctionPattern{Regex: `^\s*\w+\s+(\w+)\s*\([^)]*\)\s*{`, Type: "function"},
			FunctionPattern{Regex: `^\s*class\s+(\w+)`, Type: "class"},
		)
	}

	return patterns
}

// isValidFunctionName æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å‡½æ•°å
func isValidFunctionName(name string) bool {
	// è¿‡æ»¤æ‰å…³é”®å­—å’Œå¸¸è§è¯¯æŠ¥
	keywords := map[string]bool{
		"if": true, "for": true, "while": true, "switch": true,
		"return": true, "break": true, "continue": true,
		"true": true, "false": true, "null": true, "nil": true,
	}

	if keywords[name] {
		return false
	}

	// å‡½æ•°åè‡³å°‘3ä¸ªå­—ç¬¦
	if len(name) < 3 {
		return false
	}

	return true
}

// findCallSites æŸ¥æ‰¾å‡½æ•°çš„è°ƒç”¨ä½ç½®
func (a *CodeAnalyzer) findCallSites(functionName, sourceFile string) []string {
	callSites := []string{}

	// ä½¿ç”¨ grep åœ¨æ•´ä¸ªä»“åº“ä¸­æœç´¢å‡½æ•°å
	// ä½¿ç”¨ -l åªè¿”å›æ–‡ä»¶åï¼Œé¿å…è¾“å‡ºè¿‡å¤š
	cmd := exec.Command("grep", "-r", "-l", "--include=*.go", "--include=*.js", "--include=*.ts",
		"--include=*.py", "--include=*.java", "--include=*.rs", functionName, ".")
	cmd.Dir = a.workDir

	output, err := cmd.CombinedOutput()
	if err != nil {
		// grep è¿”å›é0çŠ¶æ€ç æ—¶ï¼ˆæœªæ‰¾åˆ°ï¼‰ä¹Ÿä¼šæœ‰ errï¼Œä½†è¿™æ˜¯æ­£å¸¸çš„
		return callSites
	}

	lines := strings.Split(string(output), "\n")
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" || line == sourceFile || strings.HasPrefix(line, "./"+sourceFile) {
			continue // è·³è¿‡å®šä¹‰æ–‡ä»¶æœ¬èº«
		}
		// å»æ‰ ./ å‰ç¼€
		line = strings.TrimPrefix(line, "./")
		callSites = append(callSites, line)
	}

	// å»é‡
	callSites = uniqueStrings(callSites)

	return callSites
}

// findTestFiles æŸ¥æ‰¾å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
func (a *CodeAnalyzer) findTestFiles(sourceFile string) []string {
	testFiles := []string{}
	language := detectLanguage(sourceFile)

	// ç”Ÿæˆå¯èƒ½çš„æµ‹è¯•æ–‡ä»¶å
	possibleTests := generateTestFileNames(sourceFile, language)

	for _, testFile := range possibleTests {
		testPath := filepath.Join(a.workDir, testFile)
		// ä½¿ç”¨ ls æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
		cmd := exec.Command("ls", testPath)
		if err := cmd.Run(); err == nil {
			testFiles = append(testFiles, testFile)
		}
	}

	return testFiles
}

// generateTestFileNames ç”Ÿæˆå¯èƒ½çš„æµ‹è¯•æ–‡ä»¶å
func generateTestFileNames(sourceFile, language string) []string {
	testNames := []string{}
	dir := filepath.Dir(sourceFile)
	base := filepath.Base(sourceFile)
	ext := filepath.Ext(base)
	nameWithoutExt := strings.TrimSuffix(base, ext)

	switch language {
	case "Go":
		// Go: foo.go -> foo_test.go
		testNames = append(testNames, filepath.Join(dir, nameWithoutExt+"_test.go"))

	case "JavaScript", "TypeScript":
		// JS/TS: foo.js -> foo.test.js, foo.spec.js, __tests__/foo.js
		testNames = append(testNames,
			filepath.Join(dir, nameWithoutExt+".test"+ext),
			filepath.Join(dir, nameWithoutExt+".spec"+ext),
			filepath.Join(dir, "__tests__", base),
			filepath.Join(dir, "__tests__", nameWithoutExt+".test"+ext),
		)

	case "Python":
		// Python: foo.py -> test_foo.py, foo_test.py, tests/test_foo.py
		testNames = append(testNames,
			filepath.Join(dir, "test_"+base),
			filepath.Join(dir, nameWithoutExt+"_test.py"),
			filepath.Join("tests", "test_"+base),
			filepath.Join("tests", dir, "test_"+base),
		)

	case "Java":
		// Java: Foo.java -> FooTest.java, tests/FooTest.java
		testNames = append(testNames,
			filepath.Join(dir, nameWithoutExt+"Test.java"),
			filepath.Join("test", dir, nameWithoutExt+"Test.java"),
			strings.Replace(filepath.Join(dir, nameWithoutExt+"Test.java"), "/main/", "/test/", 1),
		)

	case "Rust":
		// Rust: é€šå¸¸åœ¨åŒæ–‡ä»¶å†…çš„ #[cfg(test)] mod tests
		// æˆ–è€…åœ¨ tests/ ç›®å½•ä¸‹
		testNames = append(testNames,
			filepath.Join("tests", nameWithoutExt+".rs"),
			filepath.Join("tests", base),
		)
	}

	return testNames
}

// BuildAnalysisGuidance æ„å»ºåˆ†æå¼•å¯¼ï¼ˆç”¨äº Claude CLIï¼‰
func (result *DependencyAnalysisResult) BuildAnalysisGuidance() string {
	var builder strings.Builder

	builder.WriteString("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
	builder.WriteString("         DEPENDENCY IMPACT & TEST COVERAGE ANALYSIS        \n")
	builder.WriteString("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

	// 1. ä¿®æ”¹çš„å‡½æ•°/æ–¹æ³•
	if len(result.ModifiedFunctions) > 0 {
		builder.WriteString("## ğŸ”§ æ£€æµ‹åˆ°ä»¥ä¸‹å‡½æ•°/æ–¹æ³•è¢«ä¿®æ”¹:\n\n")

		// æŒ‰æ–‡ä»¶åˆ†ç»„æ˜¾ç¤º
		fileGroups := make(map[string][]FunctionInfo)
		for _, fn := range result.ModifiedFunctions {
			fileGroups[fn.File] = append(fileGroups[fn.File], fn)
		}

		for file, functions := range fileGroups {
			builder.WriteString(fmt.Sprintf("**%s**:\n", file))
			for _, fn := range functions {
				builder.WriteString(fmt.Sprintf("  - `%s` (%s)\n", fn.Name, fn.Type))
			}
			builder.WriteString("\n")
		}
	}

	// 2. ä¾èµ–å½±å“åˆ†æ
	if len(result.CallSites) > 0 {
		builder.WriteString("## ğŸ” ä¾èµ–å½±å“åˆ†æ (æ£€æµ‹åˆ°çš„è°ƒç”¨ä½ç½®):\n\n")
		builder.WriteString("**é‡è¦**: ä»¥ä¸‹å‡½æ•°åœ¨å…¶ä»–æ–‡ä»¶ä¸­è¢«è°ƒç”¨ï¼Œè¯·éªŒè¯è°ƒç”¨æ–¹æ˜¯å¦éœ€è¦æ›´æ–°:\n\n")

		for fnName, sites := range result.CallSites {
			if len(sites) > 0 {
				builder.WriteString(fmt.Sprintf("### `%s` è¢«ä»¥ä¸‹æ–‡ä»¶è°ƒç”¨:\n", fnName))
				for _, site := range sites {
					builder.WriteString(fmt.Sprintf("  - %s\n", site))
				}
				builder.WriteString("\n**å®¡æŸ¥å»ºè®®**:\n")
				builder.WriteString(fmt.Sprintf("1. ä½¿ç”¨ `Read(\"%s\")` æŸ¥çœ‹è°ƒç”¨æ–¹ä»£ç \n", sites[0]))
				if len(sites) > 1 {
					builder.WriteString("2. æ£€æŸ¥æ‰€æœ‰è°ƒç”¨æ–¹æ˜¯å¦é€‚é…äº†æ–°çš„å‡½æ•°ç­¾åæˆ–è¡Œä¸º\n")
				}
				builder.WriteString(fmt.Sprintf("3. ä½¿ç”¨ `Grep(\"%s\", output_mode=\"content\")` æŸ¥çœ‹å…·ä½“è°ƒç”¨ä¸Šä¸‹æ–‡\n", fnName))
				builder.WriteString("4. è¯„ä¼°æ˜¯å¦å­˜åœ¨ç ´åæ€§å˜æ›´ (Breaking Change)\n\n")
			}
		}
	} else if len(result.ModifiedFunctions) > 0 {
		builder.WriteString("## â„¹ï¸ ä¾èµ–å½±å“åˆ†æ:\n\n")
		builder.WriteString("æœªæ£€æµ‹åˆ°ä¿®æ”¹çš„å‡½æ•°åœ¨å…¶ä»–æ–‡ä»¶ä¸­è¢«è°ƒç”¨ï¼ˆå¯èƒ½æ˜¯å†…éƒ¨å®ç°æˆ–æ–°å¢å‡½æ•°ï¼‰\n\n")
	}

	// 3. æµ‹è¯•è¦†ç›–åˆ†æ
	builder.WriteString("## ğŸ§ª æµ‹è¯•è¦†ç›–æ£€æµ‹:\n\n")

	if len(result.TestCoverage) > 0 {
		builder.WriteString("**âœ… ä»¥ä¸‹æ–‡ä»¶æœ‰å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶**:\n\n")
		for sourceFile, testFiles := range result.TestCoverage {
			builder.WriteString(fmt.Sprintf("- `%s`\n", sourceFile))
			for _, testFile := range testFiles {
				builder.WriteString(fmt.Sprintf("  - æµ‹è¯•æ–‡ä»¶: `%s`\n", testFile))
			}
		}
		builder.WriteString("\n**å®¡æŸ¥å»ºè®®**: ä½¿ç”¨ `Read` å·¥å…·æŸ¥çœ‹æµ‹è¯•æ–‡ä»¶ï¼Œç¡®è®¤:\n")
		builder.WriteString("1. æµ‹è¯•ç”¨ä¾‹æ˜¯å¦å·²æ›´æ–°ä»¥è¦†ç›–æ–°é€»è¾‘\n")
		builder.WriteString("2. æ˜¯å¦éœ€è¦æ·»åŠ æ–°çš„æµ‹è¯•ç”¨ä¾‹\n")
		builder.WriteString("3. è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸æƒ…å†µæ˜¯å¦å……åˆ†æµ‹è¯•\n\n")
	}

	if len(result.MissingTests) > 0 {
		builder.WriteString("**âš ï¸ ä»¥ä¸‹æ–‡ä»¶ç¼ºå°‘æµ‹è¯•è¦†ç›–**:\n\n")
		for _, file := range result.MissingTests {
			builder.WriteString(fmt.Sprintf("- `%s` âŒ æœªæ‰¾åˆ°å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶\n", file))
		}
		builder.WriteString("\n**ä¸¥é‡è­¦å‘Š**: è¿™äº›æ–‡ä»¶çš„ä¿®æ”¹ç¼ºå°‘è‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œå­˜åœ¨å›å½’é£é™©!\n")
		builder.WriteString("å»ºè®®ä½œè€…è¡¥å……å•å…ƒæµ‹è¯•è¦†ç›–å…³é”®é€»è¾‘ã€‚\n\n")
	}

	// 4. å®¡æŸ¥æµç¨‹å»ºè®®
	builder.WriteString("## ğŸ“‹ å»ºè®®çš„å®¡æŸ¥æµç¨‹:\n\n")
	builder.WriteString("1. **ç†è§£å˜æ›´æ„å›¾**: é˜…è¯» PR æè¿°å’Œä¿®æ”¹çš„å®Œæ•´æ–‡ä»¶\n")
	builder.WriteString("2. **éªŒè¯å½±å“èŒƒå›´**: æ£€æŸ¥æ‰€æœ‰è°ƒç”¨æ–¹æ˜¯å¦å·²é€‚é…\n")
	builder.WriteString("3. **æµ‹è¯•è¦†ç›–æ£€æŸ¥**: ç¡®è®¤æµ‹è¯•ç”¨ä¾‹æ˜¯å¦å……åˆ†\n")
	builder.WriteString("4. **è¾¹ç•Œæ¡ä»¶å®¡æŸ¥**: ç©ºå€¼ã€é›¶å€¼ã€æœ€å¤§/æœ€å°å€¼ç­‰\n")
	builder.WriteString("5. **å®‰å…¨æ€§æ£€æŸ¥**: SQLæ³¨å…¥ã€XSSã€è®¤è¯æˆæƒç­‰\n")
	builder.WriteString("6. **æ€§èƒ½è¯„ä¼°**: å¾ªç¯å¤æ‚åº¦ã€æ•°æ®åº“æŸ¥è¯¢æ•ˆç‡ç­‰\n\n")

	return builder.String()
}

// uniqueStrings å­—ç¬¦ä¸²æ•°ç»„å»é‡
func uniqueStrings(input []string) []string {
	seen := make(map[string]bool)
	result := []string{}

	for _, str := range input {
		if !seen[str] {
			seen[str] = true
			result = append(result, str)
		}
	}

	return result
}
